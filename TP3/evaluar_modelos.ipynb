{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e3af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       model dataset  MAE_train  MAE_test  RMSE_train  \\\n",
      "4              XGBoost_A_std       A   0.163221  4.245537    0.240138   \n",
      "2         RandomForest_B_std       B   1.717307  4.727157    2.580707   \n",
      "0                LASSO_A_std       A   6.527099  7.213173    8.967902   \n",
      "3  Regresor_Polinomico_A_std       A   6.546484  7.359551    8.904705   \n",
      "1       Neural_Network_A_std       A   7.927870  7.699104   10.055259   \n",
      "\n",
      "   RMSE_test  R2_train   R2_test  gen_gap_rmse  rel_gap_rmse  \n",
      "4   6.314029  0.999529  0.709039      6.073892     25.293386  \n",
      "2   6.957816  0.945576  0.646680      4.377109      1.696089  \n",
      "0  10.391036  0.342800  0.211976      1.423134      0.158692  \n",
      "3  10.470810  0.352030  0.199830      1.566105      0.175874  \n",
      "1  10.580532  0.173768  0.182972      0.525273      0.052239  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Configuración inicial ---\n",
    "MODEL_DIR = \"./models\"  # carpeta donde están los .joblib\n",
    "OUTPUT_DIR = \"./evaluation_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Carga de datasets ---\n",
    "# A\n",
    "y_A_train = pd.read_csv(\"./A_sets/y_train_inicial.csv\")\n",
    "y_A_test  = pd.read_csv(\"./A_sets/y_test_inicial.csv\")\n",
    "X_A_train = pd.read_csv(\"./A_sets/x_A_train_std.csv\")\n",
    "X_A_test  = pd.read_csv(\"./A_sets/x_A_test_std.csv\")\n",
    "\n",
    "# B\n",
    "y_B_train = pd.read_csv(\"./B_sets/y_train_inicial.csv\")\n",
    "y_B_test  = pd.read_csv(\"./B_sets/y_test_inicial.csv\")\n",
    "X_B_train = pd.read_csv(\"./B_sets/x_B_train_std.csv\")\n",
    "X_B_test  = pd.read_csv(\"./B_sets/x_B_test_std.csv\")\n",
    "\n",
    "# --- Limpieza de datasets ---\n",
    "def drop_index_col(df):\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        return df.drop(columns=[\"Unnamed: 0\"])\n",
    "    return df\n",
    "\n",
    "X_A_train = drop_index_col(X_A_train)\n",
    "X_A_test  = drop_index_col(X_A_test)\n",
    "X_B_train = drop_index_col(X_B_train)\n",
    "X_B_test  = drop_index_col(X_B_test)\n",
    "\n",
    "# Convertir y a Series\n",
    "def y_to_series(y_df):\n",
    "    if isinstance(y_df, pd.DataFrame):\n",
    "        if y_df.shape[1] == 1:\n",
    "            return y_df.iloc[:,0].squeeze()\n",
    "        else:\n",
    "            raise ValueError(\"y tiene más de una columna; ajustar selección.\")\n",
    "    return y_df\n",
    "\n",
    "y_A_train = y_to_series(y_A_train)\n",
    "y_A_test  = y_to_series(y_A_test)\n",
    "y_B_train = y_to_series(y_B_train)\n",
    "y_B_test  = y_to_series(y_B_test)\n",
    "\n",
    "# --- Modelos a evaluar ---\n",
    "model_files = {\n",
    "    \"LASSO_A_std\": \"LASSO_A_std.joblib\",\n",
    "    \"Neural_Network_A_std\": \"Neural_Network_A_std.joblib\",\n",
    "    \"RandomForest_B_std\": \"RandomForest_B_std.joblib\",\n",
    "    \"Regresor_Polinomico_A_std\": \"Regresor_Polinomico_A_std.joblib\",\n",
    "    \"XGBoost_A_std\": \"XGBoost_A_std.joblib\"\n",
    "}\n",
    "\n",
    "# --- Funciones auxiliares ---\n",
    "def align_features_for_model(X, model):\n",
    "    Xc = X.copy()\n",
    "    if hasattr(model, \"feature_names_in_\"):\n",
    "        feat = list(model.feature_names_in_)\n",
    "        missing = [f for f in feat if f not in Xc.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Faltan columnas requeridas: {missing}\")\n",
    "        return Xc[feat]\n",
    "    elif hasattr(model, \"n_features_in_\"):\n",
    "        if model.n_features_in_ != Xc.shape[1]:\n",
    "            print(f\"WARNING: modelo espera {model.n_features_in_} features, X tiene {Xc.shape[1]}\")\n",
    "        return Xc\n",
    "    else:\n",
    "        return Xc\n",
    "\n",
    "def evaluate_preds(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "# --- Evaluación ---\n",
    "summary_rows = []\n",
    "\n",
    "for model_key, fname in model_files.items():\n",
    "    path = os.path.join(MODEL_DIR, fname)\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Modelo no encontrado: {path} -> saltando\")\n",
    "        continue\n",
    "\n",
    "    model = joblib.load(path)\n",
    "\n",
    "    if \"_A_\" in model_key or model_key.endswith(\"_A_std\"):\n",
    "        X_train, X_test, y_train, y_test = X_A_train, X_A_test, y_A_train, y_A_test\n",
    "        dataset_label = \"A\"\n",
    "    elif \"_B_\" in model_key or model_key.endswith(\"_B_std\"):\n",
    "        X_train, X_test, y_train, y_test = X_B_train, X_B_test, y_B_train, y_B_test\n",
    "        dataset_label = \"B\"\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = X_A_train, X_A_test, y_A_train, y_A_test\n",
    "        dataset_label = \"A\"\n",
    "\n",
    "    X_train_al = align_features_for_model(X_train, model)\n",
    "    X_test_al  = align_features_for_model(X_test, model)\n",
    "\n",
    "    y_pred_train = model.predict(X_train_al)\n",
    "    y_pred_test  = model.predict(X_test_al)\n",
    "\n",
    "    # Asegurar que las predicciones sean 1D\n",
    "    y_pred_train = np.ravel(y_pred_train)\n",
    "    y_pred_test = np.ravel(y_pred_test)\n",
    "\n",
    "    metrics_train = evaluate_preds(y_train, y_pred_train)\n",
    "    metrics_test  = evaluate_preds(y_test, y_pred_test)\n",
    "\n",
    "    gen_gap_rmse = metrics_test[\"RMSE\"] - metrics_train[\"RMSE\"]\n",
    "    rel_gap = gen_gap_rmse / (metrics_train[\"RMSE\"] + 1e-12)\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"model\": model_key,\n",
    "        \"dataset\": dataset_label,\n",
    "        \"MAE_train\": metrics_train[\"MAE\"],\n",
    "        \"MAE_test\": metrics_test[\"MAE\"],\n",
    "        \"RMSE_train\": metrics_train[\"RMSE\"],\n",
    "        \"RMSE_test\": metrics_test[\"RMSE\"],\n",
    "        \"R2_train\": metrics_train[\"R2\"],\n",
    "        \"R2_test\": metrics_test[\"R2\"],\n",
    "        \"gen_gap_rmse\": gen_gap_rmse,\n",
    "        \"rel_gap_rmse\": rel_gap\n",
    "    })\n",
    "\n",
    "    # --- Gráficos ---\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.scatter(y_test, y_pred_test, alpha=0.6)\n",
    "    mn, mx = min(y_test.min(), y_pred_test.min()), max(y_test.max(), y_pred_test.max())\n",
    "    plt.plot([mn,mx], [mn,mx], linestyle=\"--\")\n",
    "    plt.title(f\"Paridad TEST: {model_key}\")\n",
    "    plt.xlabel(\"y_true\")\n",
    "    plt.ylabel(\"y_pred\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"{model_key}_parity_test.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    resid = y_test - y_pred_test\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.scatter(y_pred_test, resid, alpha=0.6)\n",
    "    plt.axhline(0, linestyle=\"--\")\n",
    "    plt.title(f\"Residuos TEST: {model_key}\")\n",
    "    plt.xlabel(\"y_pred\")\n",
    "    plt.ylabel(\"residuo (y_true - y_pred)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"{model_key}_residuals_test.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# --- Resumen final ---\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(\"RMSE_test\")\n",
    "summary_df.to_csv(os.path.join(OUTPUT_DIR, \"model_evaluation_summary.csv\"), index=False)\n",
    "print(summary_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diplodatos_M07_G02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
