{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e342167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from joblib import Parallel, delayed, dump\n",
    "import multiprocessing\n",
    "import logging\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import get_scorer\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8d035",
   "metadata": {},
   "source": [
    "**La siguiente celda sirve para ver la cantidad de n√∫cleos en la CPU**, para que sepan en cuantos trabajos dividir las tareas. La idea es realizar tantos procesos paralelos como n√∫cleos tenga nuestra CPU (el dataset es chico, asique dudo que haya problemas con la RAM, pero si nos quedamos sin RAM, hay que paralelizar en menos procesos que la cantidad de n√∫cleos, o no hacerlo en absoluto). Esto es para que podamos hacer b√∫squedas m√°s exhaustivas en menos tiempo. Entiendo que scikit-learn no aprovecha GPU (seg√∫n chat GPT), pero XGBoost si üëÄ (@fede, pero si lo quer√©s aprovechar tendr√≠as que cambiar la funci√≥n, e indicarlo en un argumento al instanciar la clase$^1$).\n",
    "\n",
    "$^1$ no entiendo mucho de GPUs, capaz vos entend√©s m√°s pero comparto lo que le√≠ por si sirve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bbf0f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPU cores: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Available CPU cores: {multiprocessing.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11542275",
   "metadata": {},
   "source": [
    "## Funci√≥n para entrenar y evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db5d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizador_hiperparametros(nombre, config, X_train, y_train, X_val, y_val, nombre_dataset, metrica,\n",
    "                                busqueda='random', random_state=42, n_iter=20, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Funci√≥n para optimizar los hiperpar√°metros de un modelo dado sobre el conjunto\n",
    "    entrenamiento. La evaluaci√≥n para decidir el mejor modelo se realiza sobre el conjunto de validaci√≥n\n",
    "    (no se hace cross validation). La b√∫squeda en el espacio dehiperpar√°metros puede realizarse con random\n",
    "    search o grid search.\n",
    "    \n",
    "    Esta funci√≥n trabaja con clases de modelos de sklearn, xgboost o similares (deben soportar los m√©todos\n",
    "    fit y predict).\n",
    "    \n",
    "    Se exporta el mejor modelo obtenido con el nombre en './{nombre}_{nombre_dataset}.joblib'.\n",
    "    \n",
    "    La funci√≥n devuelve el mejor modelo obtenido en la b√∫squeda realizada, sus hiperpar√°metros su score\n",
    "    obtenido.\n",
    "    \n",
    "    Se tiene opci√≥n de paralelizar los entrenamientos en los n√∫cleos de la CPU.\n",
    "    \n",
    "    Pa√°metros:\n",
    "    ----------\n",
    "        nombre : str\n",
    "            nombre con el que se identifica al modelo. Se utilizar√° en el nombre de la variables\n",
    "            \n",
    "        config : dict\n",
    "            Diccionario con la configuraci√≥n del modelo. Debe tener los siguientes pares de clave - valor:\n",
    "                - 'modelo' : Instancia b√°sica del modelo a probar. Debe ser un objeto de sklearn, xgboost o\n",
    "                alguna librer√≠a af√≠n.\n",
    "                'params' : diccionario. Sus claves son los nombres de los hiperpar√°metros (dados en la\n",
    "                documentaci√≥n de la clase de clasificador / regresor que se utilice) y sus valores\n",
    "                corresponden a listas con los rangos o valores a ensayar.\n",
    "                    \n",
    "        X_train : pandas.DataFrame\n",
    "            Dataframe del conjunto entrenamiento (sin variable objetivo).\n",
    "        y_train : pandas.DataFrame | pandas.Serie\n",
    "            Dataframe con los valores de la variable objetivo del conjunto de entrenamiento.\n",
    "        X_val : pandas.DataFrame\n",
    "            Dataframe con las muestras del conjunto de validaci√≥n (sin variable objetivo).\n",
    "        y_val : pandas.DataFrame | pandas.Serie\n",
    "            Dataframe con los valores de la variable objetivo del conjunto de validaci√≥n.\n",
    "            \n",
    "        nombre_dataset : str\n",
    "            Nombre con el que se identifica al dataset. Se utilizar√° como sufijo en el nombre final del modelo\n",
    "            para identificar con qu√© dataset se entren√≥.\n",
    "            \n",
    "        metrica : str\n",
    "            M√©trica a utilizar. Consultar opciones v√°lidas en\n",
    "            https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-string-names. Esta funci√≥n\n",
    "            utiliza m√©tricas negativas.\n",
    "            \n",
    "        busqueda : str, default='random'\n",
    "            La forma en que se realizar√° la b√∫squeda de hiperpar√°metros √≥ptimos en el espacio de\n",
    "            hiperpar√°metros. Opciones:\n",
    "                - 'random' : random search\n",
    "                - 'grid' : grid search.\n",
    "                \n",
    "        random_state : int, default=42\n",
    "            Valor semilla para la elecci√≥n aleatoria en caso de usar random search.\n",
    "            Se fija para reproducibilidad.\n",
    "            \n",
    "        n_iter : int, default=20\n",
    "            Cantidad m√°xima de combinaciones de valores de hiperpar√°metros a probar en caso de que se use random\n",
    "            search.\n",
    "            \n",
    "        n_jobs : int, default=1\n",
    "            Cantidad de trabajos a correr en paralelo.\n",
    "            \n",
    "    Devuelve:\n",
    "    ---------\n",
    "        best_model : sklearn | xgboost model\n",
    "            M√≥delo con hiperpar√°metros √≥ptimos seg√∫n b√∫squeda realizada.\n",
    "        \n",
    "        best_params : dict\n",
    "            Diccionario con pares clave - valor dados por los nombres de los hiperpar√°metros ingresados en\n",
    "            config['params'] y sus valores √≥ptimos.\n",
    "            \n",
    "        best_score : float\n",
    "            Score obtenido por el modelo √≥ptimo (valor de la m√©trica sobre X_test).\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"üöÄ Iniciando entrenamiento para: {nombre}\")\n",
    "    \n",
    "    scorer = get_scorer(metrica)\n",
    "    \n",
    "    param_space = config[\"params\"]\n",
    "    all_param_combinations = list(itertools.product(*param_space.values()))\n",
    "    param_keys = list(param_space.keys())\n",
    "    \n",
    "    total_combinations = 1\n",
    "    for v in param_space.values():\n",
    "        total_combinations *= len(v)\n",
    "    n_iter_ajustado = min(8, total_combinations)\n",
    "\n",
    "    # Random o grid\n",
    "    if busqueda == 'grid':\n",
    "        candidates = all_param_combinations\n",
    "    elif busqueda == 'random':\n",
    "        random.seed(random_state)\n",
    "        candidates = random.sample(all_param_combinations,\n",
    "                                   min(n_iter, len(all_param_combinations)))\n",
    "    else:\n",
    "        raise ValueError(\"busqueda debe ser 'random' o 'grid'.\")\n",
    "        \n",
    "    # Funci√≥n auxiliar para entrenar y evaluar un modelo\n",
    "    def _fit_and_score(params):\n",
    "        param_dict = dict(zip(param_keys, params))\n",
    "        pipeline = Pipeline([('clf', config[\"modelo\"].set_params(**param_dict))])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        score = scorer(pipeline, X_val, y_val)\n",
    "        return param_dict, score, pipeline\n",
    "    \n",
    "    # Paralelizar entrenamiento\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_fit_and_score)(params) for params in candidates\n",
    "    )\n",
    "        \n",
    "    # Seleccionar el mejor\n",
    "    best_params, best_score, best_model = max(results, key=lambda x: x[1])\n",
    "    best_score = -best_score\n",
    "            \n",
    "    print(f\"‚úÖ {nombre}: b√∫squeda finalizada.\")\n",
    "    print(f\"üèÜ Mejor score en validaci√≥n: {best_score:.4f}\")\n",
    "    print(f\"üìå Mejores hiperpar√°metros: {best_params}\")\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Tiempo entrenando {nombre}: {elapsed:.2f} segundos\")\n",
    "\n",
    "    # Guardar modelo\n",
    "    dump(best_model, f\"./{nombre}_{nombre_dataset}.joblib\")\n",
    "\n",
    "    return best_model, best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fe985b",
   "metadata": {},
   "source": [
    "## Importo datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56964279",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos los datasets A\n",
    "\n",
    "# Etiquetas\n",
    "y_A_train = pd.read_csv(\"./A_sets/y_train_inicial.csv\")\n",
    "y_A_test = pd.read_csv(\"./A_sets/y_test_inicial.csv\")\n",
    "# Datos escaleados\n",
    "X_A_train_scaled = pd.read_csv(\"./A_sets/x_A_train_norm.csv\")\n",
    "X_A_test_scaled = pd.read_csv(\"./A_sets/x_A_test_norm.csv\")\n",
    "# Datos estandarizados\n",
    "X_A_train_std = pd.read_csv(\"./A_sets/x_A_train_std.csv\")\n",
    "X_A_test_std = pd.read_csv(\"./A_sets/x_A_test_std.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4d27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos los datasets B\n",
    "\n",
    "# Etiquetas\n",
    "y_B_train = pd.read_csv(\"./B_sets/y_train_inicial.csv\")\n",
    "y_B_test = pd.read_csv(\"./B_sets/y_test_inicial.csv\")\n",
    "# Datos escaleados\n",
    "X_B_train_scaled = pd.read_csv(\"./B_sets/x_B_train_norm.csv\")\n",
    "X_B_test_scaled = pd.read_csv(\"./B_sets/x_B_test_norm.csv\")\n",
    "# Datos estandarizados\n",
    "X_B_train_std = pd.read_csv(\"./B_sets/x_B_train_std.csv\")\n",
    "X_B_test_std = pd.read_csv(\"./B_sets/x_B_test_std.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30640c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defino diccinario para iterar sobre los datasets\n",
    "\n",
    "datasets_dict = {\n",
    "    'A_scaled' : {'x_train':X_A_train_scaled, 'y_train':y_A_train, 'x_test':X_A_test_scaled, 'y_test':y_A_test},\n",
    "    'A_std' : {'x_train':X_A_train_std, 'y_train':y_A_train, 'x_test':X_A_test_std, 'y_test':y_A_test},\n",
    "    'B_scaled' : {'x_train':X_B_train_scaled, 'y_train':y_B_train, 'x_test':X_B_test_scaled, 'y_test':y_B_test},\n",
    "    'B_std' : {'x_train':X_B_train_std, 'y_train':y_B_train, 'x_test':X_B_test_std, 'y_test':y_B_test},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e460389",
   "metadata": {},
   "source": [
    "## Ejemplos de uso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2602ab",
   "metadata": {},
   "source": [
    "### Regresi√≥n polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0f82c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "polynomial_reg_config = {\n",
    "    \"modelo\": Pipeline([\n",
    "        (\"poly\", PolynomialFeatures()),\n",
    "        (\"linreg\", LinearRegression())\n",
    "    ]),\n",
    "    \"params\": {\n",
    "        \"poly__degree\": np.arange(1, 3),\n",
    "        \"poly__interaction_only\": [True, False],\n",
    "        \"poly__include_bias\": [True, False],\n",
    "        \"linreg__positive\": [True, False]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25f001a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Dataset A_scaled\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: Regresor_Polinomico\n",
      "‚úÖ Regresor_Polinomico: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 10.4708\n",
      "üìå Mejores hiperpar√°metros: {'poly__degree': np.int64(1), 'poly__interaction_only': True, 'poly__include_bias': False, 'linreg__positive': False}\n",
      "‚è±Ô∏è Tiempo entrenando Regresor_Polinomico: 5.77 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset A_std\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: Regresor_Polinomico\n",
      "‚úÖ Regresor_Polinomico: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 10.4708\n",
      "üìå Mejores hiperpar√°metros: {'poly__degree': np.int64(1), 'poly__interaction_only': True, 'poly__include_bias': True, 'linreg__positive': False}\n",
      "‚è±Ô∏è Tiempo entrenando Regresor_Polinomico: 0.67 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset B_scaled\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: Regresor_Polinomico\n",
      "‚úÖ Regresor_Polinomico: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 10.5060\n",
      "üìå Mejores hiperpar√°metros: {'poly__degree': np.int64(1), 'poly__interaction_only': True, 'poly__include_bias': False, 'linreg__positive': False}\n",
      "‚è±Ô∏è Tiempo entrenando Regresor_Polinomico: 0.49 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset B_std\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: Regresor_Polinomico\n",
      "‚úÖ Regresor_Polinomico: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 10.5060\n",
      "üìå Mejores hiperpar√°metros: {'poly__degree': np.int64(1), 'poly__interaction_only': True, 'poly__include_bias': True, 'linreg__positive': False}\n",
      "‚è±Ô∏è Tiempo entrenando Regresor_Polinomico: 0.61 segundos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados = {}\n",
    "\n",
    "for set_conjuntos, set_dict in datasets_dict.items():\n",
    "    print(f'====================\\nDataset {set_conjuntos}\\n====================')\n",
    "    best_model, best_params, best_score = optimizador_hiperparametros(nombre='Regresor_Polinomico',\n",
    "                                                                      config=polynomial_reg_config,\n",
    "                                                                      X_train=set_dict['x_train'],\n",
    "                                                                      y_train=set_dict['y_train'],\n",
    "                                                                      X_val=set_dict['x_test'],\n",
    "                                                                      y_val=set_dict['y_test'],\n",
    "                                                                      nombre_dataset=set_conjuntos,\n",
    "                                                                      metrica='neg_root_mean_squared_error',\n",
    "                                                                      busqueda='random',\n",
    "                                                                      random_state=42,\n",
    "                                                                      n_iter=20,\n",
    "                                                                      n_jobs=4)\n",
    "    resultados[set_conjuntos] = {'mejor_modelo' : best_model,\n",
    "                                 'mejores_params' : best_params,\n",
    "                                 'mejor_score' : best_score\n",
    "                                }\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699dbaaa",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "beda0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "lasso_config = {\n",
    "    \"modelo\": Pipeline([\n",
    "        (\"poly\", PolynomialFeatures()),\n",
    "        (\"linreg\", Lasso(random_state=42))\n",
    "    ]),\n",
    "    \"params\": {\n",
    "        \"poly__degree\": np.arange(1, 6),\n",
    "        \"poly__interaction_only\": [True, False],\n",
    "        \"poly__include_bias\": [True, False],\n",
    "        \"linreg__positive\": [True, False],\n",
    "        \"linreg__alpha\": np.logspace(-4, 4, num=9, base=10)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "808c747f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Dataset A_scaled\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: LASSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e+04, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+04, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.015e+03, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.535e+03, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.669e+04, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.709e+04, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+02, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LASSO: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 10.4202\n",
      "üìå Mejores hiperpar√°metros: {'poly__degree': np.int64(1), 'poly__interaction_only': False, 'poly__include_bias': True, 'linreg__positive': False, 'linreg__alpha': np.float64(0.01)}\n",
      "‚è±Ô∏è Tiempo entrenando LASSO: 203.21 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset A_std\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: LASSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.366e+01, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.428e+03, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.784e+02, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.219e+03, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+01, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e+02, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.213e+01, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LASSO: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 10.3910\n",
      "üìå Mejores hiperpar√°metros: {'poly__degree': np.int64(1), 'poly__interaction_only': True, 'poly__include_bias': True, 'linreg__positive': False, 'linreg__alpha': np.float64(0.1)}\n",
      "‚è±Ô∏è Tiempo entrenando LASSO: 147.37 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset B_scaled\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: LASSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.946e+02, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.777e+04, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e+04, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.705e+03, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+03, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e+04, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.723e+04, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LASSO: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 10.4581\n",
      "üìå Mejores hiperpar√°metros: {'poly__degree': np.int64(1), 'poly__interaction_only': False, 'poly__include_bias': True, 'linreg__positive': False, 'linreg__alpha': np.float64(0.01)}\n",
      "‚è±Ô∏è Tiempo entrenando LASSO: 161.15 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset B_std\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: LASSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.426e+01, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.610e+03, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.407e+03, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.777e+02, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e+01, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.192e+01, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e+02, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/edu/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.135e+01, tolerance: 4.981e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LASSO: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 10.4344\n",
      "üìå Mejores hiperpar√°metros: {'poly__degree': np.int64(1), 'poly__interaction_only': True, 'poly__include_bias': True, 'linreg__positive': False, 'linreg__alpha': np.float64(0.1)}\n",
      "‚è±Ô∏è Tiempo entrenando LASSO: 108.08 segundos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados = {}\n",
    "\n",
    "for set_conjuntos, set_dict in datasets_dict.items():\n",
    "    print(f'====================\\nDataset {set_conjuntos}\\n====================')\n",
    "    best_model, best_params, best_score = optimizador_hiperparametros(nombre='LASSO',\n",
    "                                                                      config=lasso_config,\n",
    "                                                                      X_train=set_dict['x_train'],\n",
    "                                                                      y_train=set_dict['y_train'],\n",
    "                                                                      X_val=set_dict['x_test'],\n",
    "                                                                      y_val=set_dict['y_test'],\n",
    "                                                                      nombre_dataset=set_conjuntos,\n",
    "                                                                      metrica='neg_root_mean_squared_error',\n",
    "                                                                      busqueda='random',\n",
    "                                                                      random_state=42,\n",
    "                                                                      n_iter=20,\n",
    "                                                                      n_jobs=4)\n",
    "    resultados[set_conjuntos] = {'mejor_modelo' : best_model,\n",
    "                                 'mejores_params' : best_params,\n",
    "                                 'mejor_score' : best_score\n",
    "                                }\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86da4b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89dc8a9",
   "metadata": {},
   "source": [
    "#### Uso con XGBoost (espacio reducido, pruebas r√°pidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec145a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_reducido_config = {\n",
    "    \"modelo\": XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        n_jobs=1,\n",
    "        verbosity=0\n",
    "    ),\n",
    "    \"params\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [3, 5],\n",
    "        \"learning_rate\": [0.05, 0.1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59b5985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Dataset A_scaled\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: XGBoost\n",
      "‚úÖ XGBoost: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 6.8887\n",
      "üìå Mejores hiperpar√°metros: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1}\n",
      "‚è±Ô∏è Tiempo entrenando XGBoost: 2.00 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset A_std\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: XGBoost\n",
      "‚úÖ XGBoost: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 6.8887\n",
      "üìå Mejores hiperpar√°metros: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1}\n",
      "‚è±Ô∏è Tiempo entrenando XGBoost: 1.68 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset B_scaled\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: XGBoost\n",
      "‚úÖ XGBoost: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 7.1646\n",
      "üìå Mejores hiperpar√°metros: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.05}\n",
      "‚è±Ô∏è Tiempo entrenando XGBoost: 1.58 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset B_std\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: XGBoost\n",
      "‚úÖ XGBoost: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 7.1646\n",
      "üìå Mejores hiperpar√°metros: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.05}\n",
      "‚è±Ô∏è Tiempo entrenando XGBoost: 1.54 segundos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados = {}\n",
    "\n",
    "for set_conjuntos, set_dict in datasets_dict.items():\n",
    "    print(f'====================\\nDataset {set_conjuntos}\\n====================')\n",
    "    best_model, best_params, best_score = optimizador_hiperparametros(nombre='XGBoost',\n",
    "                                                                      config=xgboost_reducido_config,\n",
    "                                                                      X_train=set_dict['x_train'],\n",
    "                                                                      y_train=set_dict['y_train'],\n",
    "                                                                      X_val=set_dict['x_test'],\n",
    "                                                                      y_val=set_dict['y_test'],\n",
    "                                                                      nombre_dataset=set_conjuntos,\n",
    "                                                                      metrica='neg_root_mean_squared_error',\n",
    "                                                                      busqueda='random',\n",
    "                                                                      random_state=42,\n",
    "                                                                      n_iter=20,\n",
    "                                                                      n_jobs=4)\n",
    "    resultados[set_conjuntos] = {'mejor_modelo': best_model,\n",
    "                                 'mejores_params': best_params,\n",
    "                                 'mejor_score': best_score\n",
    "                                }\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556f3ef",
   "metadata": {},
   "source": [
    "#### Uso con XGBoost (espacio completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4edba13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgboost_config = {\n",
    "    \"modelo\": XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        n_jobs=1,  # el paralelismo lo controla la funci√≥n externa\n",
    "        verbosity=0\n",
    "    ),\n",
    "    \"params\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [3, 5, 7, 9],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "        \"subsample\": [0.6, 0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "        \"reg_alpha\": [0, 0.1, 1, 10],   # L1 regularization\n",
    "        \"reg_lambda\": [1, 10, 50]       # L2 regularization\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aad9f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Dataset A_scaled\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: XGBoost\n",
      "‚úÖ XGBoost: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 6.3140\n",
      "üìå Mejores hiperpar√°metros: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "‚è±Ô∏è Tiempo entrenando XGBoost: 8.61 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset A_std\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: XGBoost\n",
      "‚úÖ XGBoost: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 6.3140\n",
      "üìå Mejores hiperpar√°metros: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "‚è±Ô∏è Tiempo entrenando XGBoost: 8.37 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset B_scaled\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: XGBoost\n",
      "‚úÖ XGBoost: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 6.3687\n",
      "üìå Mejores hiperpar√°metros: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.1, 'reg_lambda': 10}\n",
      "‚è±Ô∏è Tiempo entrenando XGBoost: 8.48 segundos\n",
      "\n",
      "\n",
      "====================\n",
      "Dataset B_std\n",
      "====================\n",
      "üöÄ Iniciando entrenamiento para: XGBoost\n",
      "‚úÖ XGBoost: b√∫squeda finalizada.\n",
      "üèÜ Mejor score en validaci√≥n: 6.3687\n",
      "üìå Mejores hiperpar√°metros: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.1, 'reg_lambda': 10}\n",
      "‚è±Ô∏è Tiempo entrenando XGBoost: 8.52 segundos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados = {}\n",
    "\n",
    "for set_conjuntos, set_dict in datasets_dict.items():\n",
    "    print(f'====================\\nDataset {set_conjuntos}\\n====================')\n",
    "    best_model, best_params, best_score = optimizador_hiperparametros(nombre='XGBoost',\n",
    "                                                                      config=xgboost_config,\n",
    "                                                                      X_train=set_dict['x_train'],\n",
    "                                                                      y_train=set_dict['y_train'],\n",
    "                                                                      X_val=set_dict['x_test'],\n",
    "                                                                      y_val=set_dict['y_test'],\n",
    "                                                                      nombre_dataset=set_conjuntos,\n",
    "                                                                      metrica='neg_root_mean_squared_error',\n",
    "                                                                      busqueda='random',\n",
    "                                                                      random_state=42,\n",
    "                                                                      n_iter=20,\n",
    "                                                                      n_jobs=4)\n",
    "    resultados[set_conjuntos] = {'mejor_modelo': best_model,\n",
    "                                 'mejores_params': best_params,\n",
    "                                 'mejor_score': best_score\n",
    "                                }\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diplodatos_M07_G02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
